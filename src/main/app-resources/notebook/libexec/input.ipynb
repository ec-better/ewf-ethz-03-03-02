{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## ETHZ-03-03-02 Co-seismic deformation maps - Sentinel-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing pairs of S1 SAR SLC datasets using the SNAP toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"service\">Service definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "service = dict([('title', 'ETHZ-03-03-02 Co-seismic (using social media data) deformation maps'),\n",
    "                ('abstract', 'This application takes a pair of Sentinel-1 products and generates an interferogram'),\n",
    "                ('id', 'ewf-ethz-03-03-02')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter Definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output file format:\n",
    "\n",
    "* BEAM-DIMAP\n",
    "* GeoTIFF-BigTIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = dict([('id', 'format'),\n",
    "               ('value', 'GeoTIFF-BigTIFF'),\n",
    "               ('title', 'Output file format'),\n",
    "               ('abstract', 'Output file format: GeoTIFF-BigTIFF')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"runtime\">Runtime parameter definition\n",
    "    \n",
    "The variable values in this section are only relevant for the basic test case. In an actual processing context, the values are replaced by those of the parameters for the process execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input identifiers**\n",
    "\n",
    "This is the Sentinel-1 stack of master and slave products' identifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_identifiers = ('S1A_IW_SLC__1SDV_20200509T204322_20200509T204350_032493_03C355_5AE2', 'S1A_IW_SLC__1SDV_20200521T204322_20200521T204350_032668_03C89E_45B4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input references**\n",
    "\n",
    "This is the Sentinel-1 stack of catalogue references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "input_references = ('https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20200509T204322_20200509T204350_032493_03C355_5AE2', 'https://catalog.terradue.com/sentinel1/search?format=atom&uid=S1A_IW_SLC__1SDV_20200521T204322_20200521T204350_032668_03C89E_45B4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Data path**\n",
    "\n",
    "This path defines where the data is staged-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"/workspace/data/S-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"workflow\">Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the packages required for processing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snappy import jpy\n",
    "from snappy import ProductIO\n",
    "from snappy import GPF\n",
    "from snappy import HashMap\n",
    "\n",
    "import dateutil.parser as parser\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "import cioppy\n",
    "\n",
    "import gdal\n",
    "import osr\n",
    "\n",
    "from shapely.wkt import loads\n",
    "from shapely.geometry import box\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import shutil\n",
    "\n",
    "import lxml.etree as etree\n",
    "import subprocess\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphProcessor():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = etree.Element('graph')\n",
    "    \n",
    "        version = etree.SubElement(self.root, 'version')\n",
    "        version.text = '1.0'\n",
    "        self.pid = None\n",
    "        self.p = None\n",
    "   \n",
    "    def view_graph(self):\n",
    "        \n",
    "        print etree.tostring(self.root , pretty_print=True)\n",
    "        \n",
    "    def add_node(self, node_id, operator, parameters, source):\n",
    "    \n",
    "        xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "\n",
    "        if len(self.root.xpath(xpath_expr)) != 0:\n",
    "\n",
    "            node_elem = self.root.xpath(xpath_expr)[0]\n",
    "            operator_elem = self.root.xpath(xpath_expr + '/operator')[0]\n",
    "            sources_elem = self.root.xpath(xpath_expr + '/sources')[0]\n",
    "            parameters_elem = self.root.xpath(xpath_expr + '/parameters')\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "                p_elem = self.root.xpath(xpath_expr + '/parameters/%s' % key)[0]\n",
    "                p_elem.text = value\n",
    "        else:\n",
    "\n",
    "            node_elem = etree.SubElement(self.root, 'node')\n",
    "            operator_elem = etree.SubElement(node_elem, 'operator')\n",
    "            sources_elem = etree.SubElement(node_elem, 'sources')\n",
    "\n",
    "            if isinstance(source, list):\n",
    "\n",
    "                for index, s in enumerate(source):\n",
    "                    if index == 0:  \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "\n",
    "                    else: \n",
    "                        source_product_elem = etree.SubElement(sources_elem, 'sourceProduct.%s' % str(index))\n",
    "\n",
    "                    source_product_elem.attrib['refid'] = s\n",
    "\n",
    "            elif source != '':\n",
    "                source_product_elem = etree.SubElement(sources_elem, 'sourceProduct')\n",
    "                source_product_elem.attrib['refid'] = source\n",
    "\n",
    "            parameters_elem = etree.SubElement(node_elem, 'parameters')\n",
    "            parameters_elem.attrib['class'] = 'com.bc.ceres.binding.dom.XppDomElement'\n",
    "\n",
    "            for key, value in parameters.iteritems():\n",
    "\n",
    "                parameter_elem = etree.SubElement(parameters_elem, key)\n",
    "                parameter_elem.text = value\n",
    "\n",
    "        node_elem.attrib['id'] = node_id\n",
    "\n",
    "        operator_elem.text = operator \n",
    "\n",
    "    def save_graph(self, filename):\n",
    "        \n",
    "        with open(filename, 'wb') as file:\n",
    "            file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "            file.write(etree.tostring(self.root, pretty_print=True))\n",
    "     \n",
    "    def plot_graph(self):\n",
    "        \n",
    "        for node_id in self.root.xpath('/graph/node/@id'):\n",
    "            \n",
    "\n",
    "            xpath_expr = '/graph/node[@id=\"%s\"]' % node_id\n",
    "            \n",
    "            if len(self.root.xpath(xpath_expr + '/sources/sourceProduct')) != 0:\n",
    "                print(self.root.xpath(xpath_expr + '/sources/sourceProduct'))[0].attrib['refid']\n",
    "                print node_id\n",
    "            else:\n",
    "                print node_id\n",
    "        return True\n",
    "    \n",
    "    def run(self):\n",
    "        \n",
    "        fd, path = tempfile.mkstemp()\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            self.save_graph(filename=path)\n",
    "            options = ['/opt/snap6/bin/gpt',\n",
    "               '-x',\n",
    "               '-c',\n",
    "               '2048M',\n",
    "               path]\n",
    "            \n",
    "            #options = ['/workspace/software/snap6/bin/gpt',\n",
    "            #   '-x',\n",
    "            #   '-c',\n",
    "            #   '2048M',\n",
    "            #   path]\n",
    "\n",
    "            p = subprocess.Popen(options,\n",
    "                stdout=subprocess.PIPE, stdin=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "            print p.pid\n",
    "            res, err = p.communicate()\n",
    "            print res, err\n",
    "            if p.returncode != 0:\n",
    "                raise Exception('An error occurred during the execution of gpt (see log)')\n",
    "            \n",
    "        except Exception as e:\n",
    "            with open('stdout.txt', 'wb') as file:\n",
    "                file.write(res)\n",
    "                file.close()\n",
    "            with open('stderr.txt', 'wb') as file:\n",
    "                file.write(err)\n",
    "                file.close()\n",
    "            \n",
    "            raise\n",
    "        finally:\n",
    "            os.remove(path)\n",
    "        \n",
    "def get_snap_parameters(operator):\n",
    "    \n",
    "    op_spi = GPF.getDefaultInstance().getOperatorSpiRegistry().getOperatorSpi(operator)\n",
    "\n",
    "    op_params = op_spi.getOperatorDescriptor().getParameterDescriptors()\n",
    "\n",
    "    return op_params\n",
    "\n",
    "\n",
    "def getS1metadata (manifest_path):\n",
    "    \n",
    "    metadic = {}\n",
    "    \n",
    "    s1sar = 'http://www.esa.int/safe/sentinel-1.0/sentinel-1/sar/level-1'\n",
    "    safe = 'http://www.esa.int/safe/sentinel-1.0'\n",
    "    s1 = 'http://www.esa.int/safe/sentinel-1.0/sentinel-1'\n",
    "    \n",
    "    root = ET.parse(manifest_path).getroot()\n",
    "    \n",
    "    # platform\n",
    "    plat_name = root.find(\"./metadataSection/metadataObject[@ID='platform']/metadataWrap/xmlData/{%s}platform/{%s}familyName\"  % (safe, safe))\n",
    "    metadic['familyName'] = plat_name.text\n",
    "    \n",
    "    plat_num = root.find(\"./metadataSection/metadataObject[@ID='platform']/metadataWrap/xmlData/{%s}platform/{%s}number\"  % (safe, safe))\n",
    "    metadic['number'] = plat_num.text\n",
    "    \n",
    "    # orbit number\n",
    "    rel_orb_num = root.find(\"./metadataSection/metadataObject[@ID='measurementOrbitReference']/metadataWrap/xmlData/{%s}orbitReference/{%s}relativeOrbitNumber[@type='start']\"  % (safe, safe))\n",
    "    metadic['relativeOrbitNumber'] = rel_orb_num.text\n",
    "    # pass\n",
    "    rel_pass = root.find(\"./metadataSection/metadataObject[@ID='measurementOrbitReference']/metadataWrap/xmlData/{%s}orbitReference/{%s}extension/{%s}orbitProperties/{%s}pass\"  % (safe, safe, s1, s1))\n",
    "    metadic['pass'] = rel_pass.text\n",
    "    # slice\n",
    "    s1_slice_num = root.find(\"./metadataSection/metadataObject[@ID='generalProductInformation']/metadataWrap/xmlData/{%s}standAloneProductInformation/{%s}sliceNumber\"  % (s1sar, s1sar))\n",
    "    metadic['sliceNumber'] = s1_slice_num.text\n",
    "    \n",
    "    return metadic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create temporary folder\n",
    "temp_folder = 'temp'\n",
    "\n",
    "if not os.path.isdir(temp_folder):\n",
    "    os.mkdir(temp_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentinel 1 metadata\n",
    "s1metadic = getS1metadata (os.path.join(data_path, input_identifiers[0], input_identifiers[0] + '.SAFE', 'manifest.safe'))\n",
    "\n",
    "s1metadic['slave'] = input_identifiers[0]\n",
    "s1metadic['master'] = input_identifiers[1]\n",
    "\n",
    "s1metadic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### S-1 InSAR Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph = GraphProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "operator = 'Read'\n",
    "\n",
    "read_nodes = []\n",
    "\n",
    "for index, identifier in enumerate(input_identifiers):\n",
    "    \n",
    "    parameters = dict()\n",
    "\n",
    "    for param in get_snap_parameters(operator):\n",
    "    \n",
    "        if param.getName() == 'file':\n",
    "            parameters[param.getName()] = os.path.join(data_path, identifier, identifier + '.SAFE', 'manifest.safe')    \n",
    "        else:\n",
    "            parameters[param.getName()] = param.getDefaultValue()\n",
    "    node_id = 'Read(%s)' % index\n",
    "    \n",
    "    read_nodes.append(node_id)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Read', parameters, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply orbit file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Apply-Orbit-File'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit_nodes = []\n",
    "\n",
    "for index, source_node in enumerate(read_nodes):\n",
    "    \n",
    "    node_id = 'Apply-Orbit-File(%s)' % index\n",
    "    \n",
    "    orbit_nodes.append(node_id)\n",
    "    \n",
    "    mygraph.add_node(node_id, 'Apply-Orbit-File', parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOPSAR split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Split'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slave_split_nodes = []\n",
    "master_split_nodes = []\n",
    "\n",
    "for index_node, source_node in enumerate(orbit_nodes):\n",
    "    \n",
    "    for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "    \n",
    "        parameters['subswath'] =  subswath\n",
    "        parameters['selectedPolarisations'] = 'VV'\n",
    "\n",
    "        node_id = 'TOPSAR-Split(%s)' % str(index_node * 3 + index)\n",
    "    \n",
    "        if index_node == 0:\n",
    "            slave_split_nodes.append(node_id)\n",
    "        else:\n",
    "            master_split_nodes.append(node_id)\n",
    "    \n",
    "        mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-Geocoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Back-Geocoding'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if (param.getName() == 'maskOutAreaWithoutElevation'):\n",
    "        parameters[param.getName()] = 'false'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backgeo_nodes = []\n",
    "    \n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "            \n",
    "    node_id = 'Back-Geocoding(%s)' % index\n",
    "   \n",
    "    source_nodes = [slave_split_nodes[index], master_split_nodes[index]]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_nodes)\n",
    "\n",
    "    backgeo_nodes.append(node_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interferogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Interferogram'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interferogram_nodes = []\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    "            \n",
    "    node_id = 'Interferogram(%s)' % index\n",
    "   \n",
    "    source_node = backgeo_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "\n",
    "    interferogram_nodes.append(node_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOPSAR Deburst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Deburst'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deburst_nodes = []\n",
    "\n",
    "for index, subswath in enumerate(['IW1', 'IW2', 'IW3']):  \n",
    " \n",
    "    parameters['selectedPolarisations'], 'VV'\n",
    "\n",
    "    node_id = 'TOPSAR-Deburst(%s)' % index\n",
    "   \n",
    "    source_node = interferogram_nodes[index]\n",
    "    \n",
    "    mygraph.add_node(node_id, operator, parameters, source_node)\n",
    "\n",
    "    deburst_nodes.append(node_id)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOPSAR Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TOPSAR-Merge'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['selectedPolarisations'], 'VV'\n",
    "\n",
    "source_nodes = deburst_nodes\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_nodes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TopoPhaseRemoval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'TopoPhaseRemoval'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'TOPSAR-Merge'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GoldsteinPhaseFiltering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'GoldsteinPhaseFiltering'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'TopoPhaseRemoval'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Terrain-Correction'\n",
    "\n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    print(param.getName(), param.getDefaultValue())\n",
    "    \n",
    "    if param.getName() == 'nodataValueAtSea':\n",
    "        parameters[param.getName()] = 'false'\n",
    "    else:\n",
    "        parameters[param.getName()] = param.getDefaultValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_node = 'GoldsteinPhaseFiltering'\n",
    "\n",
    "parameters['outputComplex'] = 'true'\n",
    "\n",
    "node_id = operator\n",
    "\n",
    "mygraph.add_node(node_id, operator, parameters, source_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ciop = cioppy.Cioppy()\n",
    "\n",
    "search = ciop.search(end_point=input_references[0],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP') \n",
    "\n",
    "search2 = ciop.search(end_point=input_references[1],\n",
    "                     params=[],\n",
    "                     output_fields='enclosure,identifier,startdate,enddate,wkt,orbitNumber,orbitDirection,swathIdentifier,wrsLongitudeGrid',\n",
    "                     model='EOP')\n",
    "\n",
    "if (search[0]['startdate'] < search2[0]['startdate']):\n",
    "    start_date = search[0]['startdate']\n",
    "else:\n",
    "    start_date = search2[0]['startdate']\n",
    "\n",
    "if (search[0]['enddate'] > search2[0]['enddate']):\n",
    "    end_date = search[0]['enddate']\n",
    "else:\n",
    "    end_date = search2[0]['enddate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_name = 'S1_IFG_%s_%s_%s' % (\"%03d\"%int(search[0]['wrsLongitudeGrid']), \n",
    "                                    parser.parse(start_date).strftime('%Y%m%d_%H%M%S'),\n",
    "                                    parser.parse(end_date).strftime('%Y%m%d_%H%M%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = 'Write'\n",
    " \n",
    "parameters = dict()\n",
    "\n",
    "for param in get_snap_parameters(operator):\n",
    "    \n",
    "    if param.getName() == 'file':\n",
    "        \n",
    "        param_value = output_name\n",
    "             \n",
    "    elif param.getName() == 'formatName':\n",
    "                \n",
    "        param_value = 'BEAM-DIMAP'\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        param_value = param.getDefaultValue()\n",
    "    \n",
    "    \n",
    "    print param.getName(), param_value\n",
    "    \n",
    "    parameters[param.getName()] = param_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.add_node(operator, \n",
    "             operator, \n",
    "             parameters,\n",
    "             'Terrain-Correction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.view_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create phase band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ProductIO.getProductReader(\"BEAM-DIMAP\")\n",
    "\n",
    "ifg = reader.readProductNodes(output_name + '.dim', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_names = ifg.getBandNames()\n",
    "target_bands = list(band_names) \n",
    "target_bands.append(target_bands[0].replace('i_', 'phase_'))\n",
    "#target_bands.append(target_bands[0].replace('i_', 'amp_'))\n",
    "target_bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "\n",
    "targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(target_bands))\n",
    "\n",
    "for index, band in enumerate(target_bands):\n",
    "     \n",
    "    targetBand = BandDescriptor()\n",
    "    \n",
    "    if 'phase_' in band:\n",
    "       \n",
    "        targetBand.expression = 'atan2(%s, %s)' % (target_bands[1], target_bands[0])\n",
    "        \n",
    "    #elif 'amp_' in band:\n",
    "       \n",
    "    #    targetBand.expression = 'sqrt(%s * %s + %s * %s)' % (target_bands[1], target_bands[1], target_bands[0], target_bands[0])\n",
    "        \n",
    "    else:\n",
    "    \n",
    "        targetBand.expression = band\n",
    "\n",
    "    targetBand.name = band\n",
    "    targetBand.type = 'float32'\n",
    "    \n",
    "    \n",
    "    targetBands[index]= targetBand\n",
    "        \n",
    "\n",
    "parameters = HashMap()\n",
    "parameters.put('targetBands', targetBands)\n",
    "\n",
    "result = GPF.createProduct('BandMaths', parameters, ifg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProductIO.writeProduct(result,\n",
    "                       os.path.join(temp_folder, output_name + '.tif'),\n",
    "                       'GeoTIFF-BigTiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split bands into geotif files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co COMPRESS=LZW'))\n",
    "\n",
    "for index,bname in enumerate(target_bands):\n",
    "    \n",
    "    if ('coh_' in bname) or ('phase_' in bname):\n",
    "        \n",
    "        print('translating ({0}): {1}'.format(index, bname))\n",
    "        \n",
    "        gdal.Translate(os.path.join(temp_folder, bname + '.tif'), os.path.join(temp_folder, output_name + '.tif'), bandList=[index+1], creationOptions=['COMPRESS=LZW'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bands = target_bands[3:]\n",
    "target_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create RGB versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_rgb_tiff(in_tiff, out_tiff):\n",
    "    \n",
    "    temptif = os.path.join(temp_folder, 'temp.tif')\n",
    "    \n",
    "    translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co COMPRESS=LZW '\\\n",
    "                                                                    '-ot Byte ' \\\n",
    "                                                                    '-scale -3.14 3.14 0 255'))\n",
    "    gdal.Translate(temptif, \n",
    "                   in_tiff,\n",
    "                   options=translate_options)\n",
    "    \n",
    "    with open(os.path.join(temp_folder, 'color_ramp.txt'), 'wb') as file:\n",
    "        file.write('0 255 0 0 255\\n')\n",
    "        file.write('64 0 0 255 255\\n')\n",
    "        file.write('128 0 255 255 0\\n')\n",
    "        file.write('192 255 255 0 255\\n')\n",
    "        file.write('255 255 0 0 255\\n')\n",
    "    \n",
    "    \n",
    "    c = gdal.DEMProcessing(out_tiff, temptif, 'color-relief', colorFilename=os.path.join(temp_folder, 'color_ramp.txt'), options=['-alpha'])\n",
    "    c = None\n",
    "    \n",
    "    os.remove(temptif)\n",
    "    os.remove(os.path.join(temp_folder, 'color_ramp.txt'))\n",
    "    \n",
    "\n",
    "def coh_rgb(in_rgb, out_rbb):\n",
    "    \n",
    "    temptif = os.path.join(temp_folder, 'temp.tif')\n",
    "    \n",
    "    translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co COMPRESS=LZW '\\\n",
    "                                                                    '-ot Byte ' \\\n",
    "                                                                    '-scale 0 1 0 255'))\n",
    "    \n",
    "    gdal.Translate(temptif, \n",
    "                   in_rgb, \n",
    "                   options=translate_options)\n",
    "    \n",
    "    \n",
    "    translate_options = gdal.TranslateOptions(gdal.ParseCommandLine('-co COMPRESS=LZW '\\\n",
    "                                                                    '-ot Byte ' \\\n",
    "                                                                   '-b 1 -b 1 -b 1 -b 1 '))\n",
    "    \n",
    "    gdal.Translate(out_rbb, \n",
    "                   temptif, \n",
    "                   options=translate_options)\n",
    "    \n",
    "    os.remove(temptif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bname in target_bands:\n",
    "    \n",
    "    if 'coh_' in bname:\n",
    "        coh_rgb(os.path.join(temp_folder, bname + '.tif'), os.path.join(temp_folder, bname + '.rgb.tif'))\n",
    "    elif 'phase_' in bname:\n",
    "        phase_rgb_tiff(os.path.join(temp_folder, bname + '.tif'), os.path.join(temp_folder, bname + '.rgb.tif'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set alpha channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dscoh = gdal.Open(os.path.join(temp_folder, target_bands[0]+ '.rgb.tif'), gdal.OF_UPDATE)\n",
    "dsph = gdal.Open(os.path.join(temp_folder, target_bands[1]+ '.rgb.tif'), gdal.OF_UPDATE)\n",
    "\n",
    "cohband = dscoh.GetRasterBand(1).ReadAsArray()\n",
    "\n",
    "mask = np.zeros(cohband.shape, dtype=np.uint8)\n",
    "\n",
    "mask[cohband != 0] = 255\n",
    "\n",
    "dsph.GetRasterBand(4).WriteArray(mask)\n",
    "dscoh.GetRasterBand(4).WriteArray(mask)\n",
    "\n",
    "#(3, 4, 5, 6)\n",
    "dscoh.GetRasterBand(1).SetRasterColorInterpretation( dsph.GetRasterBand(1).GetRasterColorInterpretation() )\n",
    "dscoh.GetRasterBand(2).SetRasterColorInterpretation( dsph.GetRasterBand(2).GetRasterColorInterpretation() )\n",
    "dscoh.GetRasterBand(3).SetRasterColorInterpretation( dsph.GetRasterBand(3).GetRasterColorInterpretation() )\n",
    "dscoh.GetRasterBand(4).SetRasterColorInterpretation( dsph.GetRasterBand(4).GetRasterColorInterpretation() )\n",
    "\n",
    "dsph = None\n",
    "dscoh = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(os.path.join(temp_folder, target_bands[0]+ '.tif'), target_bands[0]+ '.tif')\n",
    "shutil.move(os.path.join(temp_folder, target_bands[1]+ '.tif'), target_bands[1]+ '.tif')\n",
    "shutil.move(os.path.join(temp_folder, target_bands[0]+ '.rgb.tif'), target_bands[0]+ '.rgb.tif')\n",
    "shutil.move(os.path.join(temp_folder, target_bands[1]+ '.rgb.tif'), target_bands[1]+ '.rgb.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Properties files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eop_metadata(metadata):\n",
    "\n",
    "    opt = 'http://www.opengis.net/opt/2.1'\n",
    "    om  = 'http://www.opengis.net/om/2.0'\n",
    "    gml = 'http://www.opengis.net/gml/3.2'\n",
    "    eop = 'http://www.opengis.net/eop/2.1'\n",
    "    sar = 'http://www.opengis.net/sar/2.1'\n",
    "    \n",
    "    root = etree.Element('{%s}EarthObservation' % sar)\n",
    "\n",
    "    phenomenon_time = etree.SubElement(root, '{%s}phenomenonTime' % om)\n",
    "\n",
    "    time_period = etree.SubElement(phenomenon_time, '{%s}TimePeriod' % gml)\n",
    "\n",
    "    begin_position = etree.SubElement(time_period, '{%s}beginPosition'  % gml)\n",
    "\n",
    "    end_position = etree.SubElement(time_period, '{%s}endPosition'  % gml)\n",
    "\n",
    "    procedure = etree.SubElement(root, '{%s}procedure' % om)\n",
    "\n",
    "    earth_observation_equipment = etree.SubElement(procedure, '{%s}EarthObservationEquipment' % eop)\n",
    "\n",
    "    acquisition_parameters = etree.SubElement(earth_observation_equipment, '{%s}acquisitionParameters' % eop)\n",
    "\n",
    "    acquisition = etree.SubElement(acquisition_parameters, '{%s}Acquisition' % sar)\n",
    "\n",
    "    orbit_number = etree.SubElement(acquisition, '{%s}orbitNumber' % eop)\n",
    "\n",
    "    wrs_longitude_grid = etree.SubElement(acquisition, '{%s}wrsLongitudeGrid' % eop)\n",
    "\n",
    "    polarisation_channels = etree.SubElement(acquisition, '{%s}polarisationChannels' % eop)\n",
    "    \n",
    "    feature_of_interest = etree.SubElement(root, '{%s}featureOfInterest' % om)\n",
    "    footprint = etree.SubElement(feature_of_interest, '{%s}Footprint' % eop)\n",
    "    multi_extentOf = etree.SubElement(footprint, '{%s}multiExtentOf' % eop)\n",
    "    multi_surface = etree.SubElement(multi_extentOf, '{%s}MultiSurface' % gml)\n",
    "    surface_members = etree.SubElement(multi_surface, '{%s}surfaceMembers' % gml)\n",
    "    polygon = etree.SubElement(surface_members, '{%s}Polygon' % gml)    \n",
    "    exterior = etree.SubElement(polygon, '{%s}exterior' % gml)  \n",
    "    linear_ring = etree.SubElement(exterior, '{%s}LinearRing' % gml) \n",
    "    poslist = etree.SubElement(linear_ring, '{%s}posList' % gml) \n",
    "\n",
    "\n",
    "    result = etree.SubElement(root, '{%s}result' % om)\n",
    "    earth_observation_result = etree.SubElement(result, '{%s}EarthObservationResult' % opt)\n",
    "    cloud_cover_percentage = etree.SubElement(earth_observation_result, '{%s}cloudCoverPercentage' % opt)\n",
    "    \n",
    "    metadata_property = etree.SubElement(root, '{%s}metaDataProperty' % eop)\n",
    "    earth_observation_metadata = etree.SubElement(metadata_property, '{%s}EarthObservationMetaData' % eop)\n",
    "    identifier = etree.SubElement(earth_observation_metadata, '{%s}identifier' % eop)\n",
    "    \n",
    "    begin_position.text = metadata['startdate']\n",
    "    end_position.text = metadata['enddate']\n",
    "    #orbit_number.text = metadata['orbitNumber']\n",
    "    wrs_longitude_grid.text = metadata['wrsLongitudeGrid']\n",
    "    \n",
    "    coords = np.asarray([t[::-1] for t in list(loads(metadata['wkt']).exterior.coords)]).tolist()\n",
    " \n",
    "    pos_list = ''\n",
    "    for elem in coords:\n",
    "        pos_list += ' '.join(str(e) for e in elem) + ' '   \n",
    "\n",
    "    poslist.attrib['count'] = str(len(coords))\n",
    "    poslist.text = pos_list\n",
    "    \n",
    "    \n",
    "    identifier.text = metadata['identifier'] \n",
    "\n",
    "    return etree.tostring(root, pretty_print=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = gdal.Open(target_bands[0] + '.tif')\n",
    "ulx, xres, xskew, uly, yskew, yres  = src.GetGeoTransform()\n",
    "\n",
    "max_x = ulx + (src.RasterXSize * xres)\n",
    "min_y = uly + (src.RasterYSize * yres)\n",
    "min_x = ulx \n",
    "max_y = uly\n",
    "\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromWkt(src.GetProjection())\n",
    "\n",
    "target = osr.SpatialReference()\n",
    "target.ImportFromEPSG(4326)\n",
    "\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "result_wkt = box(transform.TransformPoint(min_x, min_y)[0],\n",
    "        transform.TransformPoint(min_x, min_y)[1],\n",
    "        transform.TransformPoint(max_x, max_y)[0],\n",
    "        transform.TransformPoint(max_x, max_y)[1]).wkt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search[0]['identifier'] = output_name\n",
    "search[0]['wkt'] = result_wkt\n",
    "\n",
    "search[0]['startdate'] = start_date\n",
    "search[0]['enddate'] = end_date\n",
    "\n",
    "#eop_xml = output_name + '.xml'\n",
    "#with open(eop_xml, 'wb') as file:\n",
    "#    file.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "#    file.write(eop_metadata(search[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bname in target_bands:\n",
    "    \n",
    "    with open(bname + '.tif.properties', 'wb') as file:\n",
    "        \n",
    "        file.write('title=Output %s\\n' % bname)\n",
    "        file.write('date=%s/%s\\n' % (start_date, end_date))\n",
    "        \n",
    "        #s1metadic\n",
    "        \n",
    "        file.write('Master\\\\ SLC\\\\ Product = %s\\n' % s1metadic['master'])\n",
    "        file.write('Slave\\\\ SLC\\\\ Product = %s\\n' % s1metadic['slave'])\n",
    "        \n",
    "        file.write('Sensor\\\\ Name = %s\\n' % (s1metadic['familyName']))\n",
    "        \n",
    "        file.write('Orbit\\\\ Direction = %s\\n' % s1metadic['pass'])\n",
    "        file.write('Relative\\\\ Orbit\\\\ Number = %s\\n' % s1metadic['relativeOrbitNumber'])\n",
    "        \n",
    "        file.write('geometry=%s' % (result_wkt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for properties_file in ['result', 'stage-in']:\n",
    "\n",
    "    if properties_file == 'result':\n",
    "        title = 'Reproducibility notebook'\n",
    "    else: \n",
    "        title = 'Reproducibility stage-in notebook'\n",
    "        \n",
    "    with open(properties_file + '.properties', 'wb') as file:\n",
    "        \n",
    "        file.write('title=%s\\n' % title)\n",
    "        file.write('date=%s/%s\\n' % (start_date, end_date))\n",
    "        file.write('geometry=%s' % (search[0]['wkt']))\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(output_name + '.data')\n",
    "os.remove(output_name + '.dim')\n",
    "\n",
    "shutil.rmtree(temp_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This work is licenced under a [Attribution-ShareAlike 4.0 International License (CC BY-SA 4.0)](http://creativecommons.org/licenses/by-sa/4.0/) \n",
    "\n",
    "YOU ARE FREE TO:\n",
    "\n",
    "* Share - copy and redistribute the material in any medium or format.\n",
    "* Adapt - remix, transform, and built upon the material for any purpose, even commercially.\n",
    "\n",
    "UNDER THE FOLLOWING TERMS:\n",
    "\n",
    "* Attribution - You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.\n",
    "* ShareAlike - If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
